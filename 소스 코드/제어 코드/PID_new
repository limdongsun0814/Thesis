#!/usr/bin/env python
import pyzbar.pyzbar as pyzbar
import rospy
import csv
import math
import tf2_msgs.msg
from geometry_msgs.msg import Twist
import tf2_ros
from darknet_ros_msgs.msg import BoundingBoxes
from nav_msgs.msg import Odometry
from std_msgs.msg import String
from tf.transformations import euler_from_quaternion
# from tensorflow.python.keras.backend import set_session
from sensor_msgs.msg import Image,CompressedImage
import cv2
from cv_bridge import CvBridge
import time
import sys
import numpy as np
import sys, select, os
from tensorflow.python.keras.models import load_model
# from tensorflow.python.keras import layers
import tensorflow as tf
from sklearn import preprocessing
# from tensorflow.python.keras import models
# from tensorflow.python.keras import metrics
# from tensorflow.python.keras import losses
# from tensorflow.python.keras import optimizers
# from tensorflow.python.keras import datasets
# from tensorflow.python.keras.layers import Dropout
# from tensorflow.python.keras.utils import plot_model
if os.name == 'nt':
  import msvcrt
else:
  import tty, termios
import matplotlib.pyplot as plt
rospy.init_node('casenter')
twist = rospy.Publisher('/cmd_vel',Twist,queue_size=10)
str_pub = rospy.Publisher('/find_robot',String,queue_size=10)
pub=Twist()
pub.linear.x = 0.0; pub.linear.y = 0.0; pub.linear.z = 0.0
pub.angular.x = 0.0; pub.angular.y = 0.0; pub.angular.z = -0.5
twist.publish(pub)
count,error_sum,error_sum_speed,lost_error=0,0,0,0
bounding_box_x_min,bounding_box_y_min,bounding_box_x_max,bounding_box_y_max=0,0,0,0
key=''
find_robot=0
file=open("distance_angle.csv","w")
csv_file=csv.writer(file)
#horizontal field of view: 53.5
#Vertical field of view: 41.41
#640x320
img_raw = []
degree=90
distance=50
x_real = 0
y_real = 50
save="NO"
img1 = cv2.imread('../image_raw_screenshot_16.06.20222.png',0)
sift = cv2.ORB_create()
# model._make_predict_function()
graph = tf.get_default_graph()
fourcc = cv2.VideoWriter_fourcc(*'DIVX')
find_robot_video = cv2.VideoWriter('50 0.avi', fourcc, 30, (640, 480))
another_video = cv2.VideoWriter('another_video.avi', fourcc, 30, (300, 200))
kp1, des1 = sift.detectAndCompute(img1,None)
init_model = False
print 'start'
def decode(im):
    # Find barcodes and QR codes
    decodedObjects = pyzbar.decode(im)

    # Print results
    for obj in decodedObjects:
        print('Type : ', obj.type)
        print('Data : ', obj.data, '\n')
        a=[]
        #print(int(obj.data))
        cnt = 0
        for i in str(int(obj.data)):
            a.append(int(i))
        for i in range(8-len(a)):
            a.insert(0,0)
        print(a)
        error_code = 0
        for i in range(len(a)-1):
            if cnt%2==0:
                error_code=error_code+a[i]*3
            else:
                error_code=error_code+a[i]*1

            cnt=cnt+1
        print((10-(error_code%10))%10)
    return decodedObjects
class PID():
	def __init__(self, kp, ki, kd,target,time,dis):
		self.kp = kp
		self.ki = ki
		self.kd = kd
		self.error_sum = target-dis
		self.target = target
		self.time_old = time
		self.error_old = 0
		self.cnt = 0
		self.value_avg = 0
	def height_to_distance(self, plx,h):
		#dis = (8406.536 / h) - 4.7694054
		dis = 12.9/(math.tan(math.atan(math.tan(math.radians(41.41))*h/480)-math.atan(math.tan(math.radians(41.41))*\
			 (186-plx)/480))+math.tan(math.atan(math.tan(math.radians(41.41))*(186-plx)/480)))
		return dis
	def center_to_angle(self, ctr):
		#dis = (8406.536 / h) - 4.7694054
		angle=90-math.degrees(math.atan(math.tan(math.radians(53.5/2))*ctr/320))
		return angle
	def pid_contor(self, control, time):
		self.error = self.target - control
		self.error_sum = self.error_sum + self.error
		self.dt = time - self.time_old

		speed = self.kp*self.error + \
				self.ki*self.error_sum *self.dt + \
				self.kd*(self.error_old - self.error)/self.dt
		#print('dt: ',self.dt,self.kp*self.error, self.ki*self.error_sum *self.dt,
		#self.kd*(self.error_old - self.error)/self.dt)
		self.time_old = time
		self.error_old = self.error
		return speed

	def filter(self,value):

		if self.cnt == 10:
			self.cnt=0
			self.value_avg=0

		self.value_avg = (self.value_avg*self.cnt) / (self.cnt+1) + \
			value/(self.cnt+1)
		self.cnt = self.cnt+1

		return self.value_avg
#kp,ki,kd
speed = PID(0.0005,0.0000,0.003,50,rospy.get_time(),0)
angle = PID(0.0005,0.0000,0.0009,90,rospy.get_time(),0)
init=True
img_last=np.empty((640,480),dtype=np.uint8)
if os.name != 'nt':
	settings = termios.tcgetattr(sys.stdin)

def getKey():
	global key,settings
	if os.name == 'nt':
		return msvcrt.getch()
	tty.setraw(sys.stdin.fileno())
	rlist, _, _ = select.select([sys.stdin], [], [], 0.1)
	if rlist:
		key = sys.stdin.read(1)
	else:
		if key == 'r':
			key='r'
		else:
			key=''

	termios.tcsetattr(sys.stdin, termios.TCSADRAIN, settings)
	return key
time=0.0


def odom(cmd_val):
	global bounding_box_y_min,bounding_box_x_min,bounding_box_y_max,bounding_box_x_max,find_robot,img_raw,init_model,time,model,str_pub,find_robot_video \
			,another_video,distance,save,x_real,y_real
		#,model#,graph
	# print 'find bounding boxes id: ', cmd_val.bounding_boxes[0]
	# with graph.as_default():
	for i in range(len(cmd_val.bounding_boxes)):
		# print 'find bounding boxes id: ', i, cmd_val.bounding_boxes[i].Class

		if cmd_val.bounding_boxes[i].Class == 'my_robot' and cmd_val.bounding_boxes[i].probability>0.4:
			bounding_box_x_min=cmd_val.bounding_boxes[i].xmin
			bounding_box_y_min=cmd_val.bounding_boxes[i].ymin
			bounding_box_x_max=cmd_val.bounding_boxes[i].xmax
			bounding_box_y_max=cmd_val.bounding_boxes[i].ymax
			# print 'find bounding boxes id: ', i, cmd_val.bounding_boxes[i].Class
		# decodedObjects = decode(img_raw)
		# cv2.imshow("img_raw4", img_raw)
		# cv2.waitKey(1)
		# if int(decodedObjects[0][0])==1010015:

			if bounding_box_y_min - 20 > 0:
				y_min = bounding_box_y_min - 20
				y_add = 20
			else:
				y_min = 0
				y_add = 20
			if bounding_box_x_min - 20 > 0:
				x_min = bounding_box_x_min - 20
				x_add = 20
			else:
				x_min = 0
				x_add = 0
			if bounding_box_y_max + 20 < 480:
				y_max = bounding_box_y_max + 20
			else:
				y_max = 480
			if bounding_box_x_max + 20 < 640:
				x_max = bounding_box_x_max + 20
			else:
				x_max = 640

			img = img_raw[y_min: y_max, x_min: x_max]
			img_resize = cv2.resize(img, (300, 200), interpolation=cv2.INTER_LINEAR)
			hsv_img = cv2.cvtColor(img_resize, cv2.COLOR_BGR2HSV)
			hsv_img_a = cv2.cvtColor(img_raw, cv2.COLOR_BGR2HSV)

			channels = cv2.split(hsv_img)
			colors = ('h', 's', 'v')

			for (ch, color) in zip(channels, colors):
				if color == 'h':

					if init_model == False:
						init_model = True

						model = load_model('/home/limdongsun/catkin_ws/src/darknet_ros/darknet_ros/src/modelv3.h5',
										   compile=False)

					hist,asasas = np.histogram([ch], 360,[0,360])
					data=np.array(hist.T,dtype=np.float64)
					data=data.reshape((1,360))
					# print rospy.get_time(),cmd_val.bounding_boxes[i].probability

					time = rospy.get_time()

					yhat = model.predict_classes(data)
					# print rospy.get_time()-time
					# cv2.imshow("img_raw4", img_resize)
					# # cv2.waitKey(1)
					# key = getKey()
					# # print key
					# if key == 'q':
					# 	print("==========STOP==========")
					# 	save = "NO"
					# if key == 'w':
					# 	print("==========UP==========")
					# 	# degree=degree+5
					# 	# distance = distance + 5
					# if key == 'e':
					# 	print("==========DOWN==========")
					# 	# degree=degree-5
					# 	# distance = distance - 5
					# if key == 'r':
					# 	print("==========SAVING==========")
					# 	if yhat == 0 :
					# 		csv_file.writerow([distance, center_y, h])
							# find_robot_video.write(img_resize)
						# else:
							# another_video.write(img_resize)
						# img_resize = cv2.resize(img, (300, 200), interpolation=cv2.INTER_LINEAR)
						# # red_hsv = cv2.cvtColor(img_resize, cv2.COLOR_BGR2HSV)
						# #
						# # channels = cv2.split(red_hsv)
						# # colors = ('b', 'g', 'r')
						# # for (ch, color) in zip(channels, colors):
						# # 	if color == 'b':
						# # 		hist = cv2.calcHist([ch], [0], None, [100], [0, 360])
						# out.write(img_resize)
						# save = "YES"
					str_pub.publish(str(yhat))
					# yhat = model.predict(np.array(reshape_hist_t, dtype=np.float64))
					# yhat = model.run(aaaaaaaaaa)
					# yhat = 1
					if yhat == 0 :
						find_robot=1
						# print("find robot")
					else:
						find_robot=0
			# 			# print("not find robot")
			# if find_robot == 1:
			# 	find_robot = 0
			# 	# print(img_raw.dtype)
			# 	# print(img_last.dtype)
			#
			# 	# kp2, des2 = sift.detectAndCompute(img, None)
			# 	lower_orange = (10, 101, 74)  #
			# 	upper_orange = (77, 225, 166)  #
			# 	hsv_img_aa=cv2.resize(hsv_img_a, (600, 400))
			# 	thresh = cv2.inRange(hsv_img_aa, lower_orange, upper_orange)
			# 	kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 7))
			# 	thresh_open = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
			# 	test=np.count_nonzero(thresh_open > 1.0, axis=0)
			# 	test2=np.count_nonzero(thresh_open > 1.0, axis=1)
			#
			# 	key = getKey()
			# 	# print key
			#
			# 	fourcc = cv2.VideoWriter_fourcc(*'DIVX')
			# 	if key == 'q':
			# 		print("==========STOP==========")
			# 		save = "NO"
			# 	if key == 'w':
			# 		print("==========UP==========")
			# 		y_real=y_real+5
			# 		# video_name =str(y_real)+' '+str(x_real)+'.avi'
			# 		# find_robot_video = cv2.VideoWriter(video_name, fourcc, 30, (640, 480))
			# 	# degree=degree+5
			# 	# 	distance = distance + 5
			# 	if key == 's':
			# 		print("==========DOWN==========")
			# 		y_real=y_real-5
			# 		# video_name =str(y_real)+' '+str(x_real)+'.avi'
			# 		# find_robot_video = cv2.VideoWriter(video_name, fourcc, 30, (640, 480))
			#
			# 	if key == 'a':
			# 		print("==========left==========")
			# 		x_real=x_real-5
			# 		# video_name =str(y_real)+' '+str(x_real)+'.avi'
			# 		# find_robot_video = cv2.VideoWriter(video_name, fourcc, 30, (640, 480))
			# 	if key == 'd':
			# 		print("==========right=========")
			# 		x_real=x_real+5
			# 		# video_name =str(y_real)+' '+str(x_real)+'.avi'
			# 		# find_robot_video = cv2.VideoWriter(video_name, fourcc, 30, (640, 480))
			# 	# degree=degree-5
			# 	# 	distance = distance - 5
			# 	if key == 'r':
			# 		print("==========SAVING==========")
			# 		if yhat == 0:
			# 			test_list=test.tolist()
			# 			test_list=test_list+test2.tolist()
			# 			test_list.append(y_real)
			# 			test_list.append(x_real)
			# 			csv_file.writerow(test_list)
			# 			# find_robot_video.write(frame)
			# 			# out.release()
			# 	print('save',save,'x; ',x_real,'y; ',y_real,'video name; ',str(y_real)+' '+str(x_real)+'.avi')
			# 	# print(test.shape,test)
			# 	cv2.imshow("img_raw4", thresh_open)
			# 	cv2.waitKey(1)
			# 	(x, y) = (0, 0)
			# 	cnt, _, stats, centroids = cv2.connectedComponentsWithStats(thresh_open)
			# 	a = np.array(stats)
			# 	stats = a.tolist()
			# 	stats.sort(key=lambda n: n[4], reverse=True)
			# 	# (x, y, w, h, s) = stats[find_argmax]
			# 	# ctr = centroids[find_argmax]
			#
			# 	if cnt == 1:
			# 		(x, y, w, h, s) = stats[0]
			# 		ctr = centroids[0]
			# 	else:
			# 		del stats[0]
			# 		find_argmax = np.argmax(stats, axis=0)
			# 		# print(find_argmax)
			# 		(x, y, w, h, s) = stats[find_argmax[4]]
			# 		ctr = centroids[find_argmax[4]]
			# 	if 100 < s < 20000:
			# 		pass
			#
			# 	if x_add == 20:
			# 		center = ctr[0] + bounding_box_x_min - x_add
			# 	else:
			# 		center = ctr[0] + bounding_box_x_min
			# 	if y_add == 20:
			# 		center_y = y + bounding_box_y_min - y_add
			# 	else:
			# 		center_y = y + bounding_box_y_min
				# print(center,centroids,stats,ctr)

				# if 320-center>0:
				#	tan=math.degrees(math.atan(320*math.tan(math.radians(62.2/1))/float(320-center)))
				# else:
				#	tan = math.degrees(math.atan(320 * math.tan(math.radians(62.2 / 1)) / float(320 - center)))+180

				# lin=90-(320-center)*(90-62.2)/(320*1)

				# print("center: ", 320 - center, "arctan: ", tan, "lin: ", lin, "angle: ", degree,"h: ",h, "save?: ", save)

				dis = speed.height_to_distance(center_y, h)
				cut = speed.pid_contor(dis, time)
				deg = angle.center_to_angle(320 - center)
				agl = angle.pid_contor(deg, time)
				print("dis: ", dis,  "deg: ", deg, 'y; ',dis*math.cos(math.radians(deg-90)),'x; ',dis*math.sin(math.radians(deg-90)))  # , "lin: ", lin, "angle: ", degree, "h: ", h, "save?: ", save)

				# print("center_y: ", center_y, "h: ", h,"distance: ", distance,"save?: ", save)#, "lin: ", lin, "angle: ", degree, "h: ", h, "save?: ", save)
				# pub.linear.x = -cut;         pub.linear.y = 0.0;		pub.linear.z = 0.0
				# pub.angular.x = 0.0;		pub.angular.y = 0.0;		pub.angular.z = agl*3
				# twist.publish(pub)
				# cv2.waitKey(1)

				x_add = 0

				# cv2.imshow("img_last",img_last)
				# cv2.imshow(np.uint8(disparity), 'gray')

				# print(time,"sec"," / ","distance: ", dis, "cm",'cut: ',cut,'angle_speed: ',agl)
				# for i in range(len(img_raw)):
				# 	img_raw[i][int(center)] = [0, 0, 255]
			# print(len(img_raw))
			#
			# FLANN_INDEX_KDTREE = 1
			# index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
			# search_params = dict(checks=100)  # or pass empty dictionary
			# flann = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
			# 	# cv2.FlannBasedMatcher(index_params, search_params)
			# matches = flann.match(des1, des2)
			# 					  # , k=2)
			#
			# matches = sorted(matches, key=lambda x:x.distance)
			#
			# src_pts = np.float32([kp1[m.queryIdx].pt for m in matches])
			# dst_pts = np.float32([kp2[m.trainIdx].pt for m in matches])
			#
			# mtrx, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0,confidence=0.1)
			# h, w = img1.shape[:2]
			# pts = np.float32([[[0, 0]], [[0, h - 1]], [[w - 1, h - 1]], [[w - 1, 0]]])
			# dst = cv2.perspectiveTransform(pts, mtrx)
			# # img = cv2.polylines(img, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)
			#
			# # matchesMask = [[0, 0] for i in range(len(matches))]
			# # for i, (m, n) in enumerate(matches):
			# # 	if m.distance < 0.7 * n.distance:
			# # 		matchesMask[i] = [1, 0]
			# #
			# # print matchesMask.count([1,0])
			# # draw_params = dict(matchColor=(0, 255, 0),
			# # 				   singlePointColor=(255, 0, 0),
			# # 				   matchesMask=matchesMask,
			# # 				   flags=0)
			# img4 = cv2.drawMatches(img1, kp1, img, kp2, matches, None, flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)
			#
			# matchesMask = mask.ravel().tolist()
			#
			# img3 = cv2.drawMatches(img1, kp1, img, kp2, matches, None, matchesMask = matchesMask, flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)
			#
			# accuracy = float(mask.sum()) / mask.size
			# print("accuracy: %d/%d(%.2f%%)" % (mask.sum(), mask.size, accuracy))
			# cv2.imshow("img_raw", img3)
			# cv2.imshow("img_raw4", img4)
			# cv2.waitKey(1)
			# cv2.waitKey(1)

			else:
				pub.linear.x = 0.0;
				pub.linear.y = 0.0;
				pub.linear.z = 0.0
				pub.angular.x = 0.0;
				pub.angular.y = 0.0;
				pub.angular.z = 0
	# twist.publish(pub)

def image_callback(msg):
	global bounding_box_y_min,bounding_box_x_min,bounding_box_y_max,bounding_box_x_max,find_robot,init,img_last,disparity
	global degree,save,distance,kp1, des1,sift,out,img_raw
	bridge = CvBridge()

	find_robot = 1
	img_raw = bridge.imgmsg_to_cv2(msg, "bgr8")


		# print(img_raw.dtype)
		# print(img_last.dtype)

		# kp2, des2 = sift.detectAndCompute(img, None)
	lower_orange = (10, 101, 74)  #
	upper_orange = (77, 225, 166)  #
	hsv_img_aa = cv2.resize(hsv_img_a, (600, 400))
	thresh = cv2.inRange(hsv_img_aa, lower_orange, upper_orange)
	kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 7))
	thresh_open = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)
	test = np.count_nonzero(thresh_open > 1.0, axis=0)
	test2 = np.count_nonzero(thresh_open > 1.0, axis=1)

	key = getKey()
	# print key

	fourcc = cv2.VideoWriter_fourcc(*'DIVX')
	if key == 'q':
		print("==========STOP==========")
		save = "NO"
	if key == 'w':
		print("==========UP==========")
		y_real = y_real + 5
	# video_name =str(y_real)+' '+str(x_real)+'.avi'
	# find_robot_video = cv2.VideoWriter(video_name, fourcc, 30, (640, 480))
	# degree=degree+5
	# 	distance = distance + 5
	if key == 's':
		print("==========DOWN==========")
		y_real = y_real - 5
	# video_name =str(y_real)+' '+str(x_real)+'.avi'
	# find_robot_video = cv2.VideoWriter(video_name, fourcc, 30, (640, 480))

	if key == 'a':
		print("==========left==========")
		x_real = x_real - 5
	# video_name =str(y_real)+' '+str(x_real)+'.avi'
	# find_robot_video = cv2.VideoWriter(video_name, fourcc, 30, (640, 480))
	if key == 'd':
		print("==========right=========")
		x_real = x_real + 5
	# video_name =str(y_real)+' '+str(x_real)+'.avi'
	# find_robot_video = cv2.VideoWriter(video_name, fourcc, 30, (640, 480))
	# degree=degree-5
	# 	distance = distance - 5
	if key == 'r':
		print("==========SAVING==========")
		if yhat == 0:
			test_list = test.tolist()
			test_list = test_list + test2.tolist()
			test_list.append(y_real)
			test_list.append(x_real)
			csv_file.writerow(test_list)
	# find_robot_video.write(frame)
	# out.release()
	print('save', save, 'x; ', x_real, 'y; ', y_real, 'video name; ', str(y_real) + ' ' + str(x_real) + '.avi')
	# print(test.shape,test)
	cv2.imshow("img_raw4", thresh_open)
	cv2.waitKey(1)
	(x, y) = (0, 0)
	cnt, _, stats, centroids = cv2.connectedComponentsWithStats(thresh_open)
	a = np.array(stats)
	stats = a.tolist()
	stats.sort(key=lambda n: n[4], reverse=True)
	# (x, y, w, h, s) = stats[find_argmax]
	# ctr = centroids[find_argmax]

	if cnt == 1:
		(x, y, w, h, s) = stats[0]
		ctr = centroids[0]
	else:
		del stats[0]
		find_argmax = np.argmax(stats, axis=0)
		# print(find_argmax)
		(x, y, w, h, s) = stats[find_argmax[4]]
		ctr = centroids[find_argmax[4]]
	if 100 < s < 20000:
		pass

	if x_add == 20:
		center = ctr[0] + bounding_box_x_min - x_add
	else:
		center = ctr[0] + bounding_box_x_min
	if y_add == 20:
		center_y = y + bounding_box_y_min - y_add
	else:
		center_y = y + bounding_box_y_min



	#cv2.imshow("ROI", roi)
	#cv2.imshow('ori', img)
	#cv2.imshow('result', thresh)
	#cv2.imshow('open_result', thresh_open)
	#cv2.imshow("img_raw",img_raw)
	#cv2.imshow("img",img)
	#cv2.imshow("bgr_img",bgr_img)
	#cv2.imshow("hsv_img",hsv_img)
rospy.Subscriber("/darknet_ros/bounding_boxes",BoundingBoxes,odom)
#rospy.Subscriber("/odom",Odometry,trun)
rospy.Subscriber("/camera/image_raw",Image,image_callback)
#while(1):
twist.publish(pub)
rospy.spin()